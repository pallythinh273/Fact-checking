{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = json.load(open('../Data/merged_data_file.json'))\n",
    "data = []\n",
    "for key, value in context.items():\n",
    "    temp = {\n",
    "        'ID': key,\n",
    "        'Context': value['context']\n",
    "        }\n",
    "    data.append(temp)\n",
    "context = pd.DataFrame(data)\n",
    "context['ID'] = context['ID'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "jd_data = json.load(open('../Data/final_data_new.json'))\n",
    "df = pd.json_normalize(jd_data)\n",
    "\n",
    "df.rename(columns = {'_id':'ID','claim':'Claim', 'metadata.context_id':'Context_ID', 'metadata.label':'Verdict', 'metadata.evidence':'Evidence'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12948 entries, 0 to 12947\n",
      "Data columns (total 5 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   ID          12948 non-null  object\n",
      " 1   Claim       12948 non-null  object\n",
      " 2   Context_ID  12948 non-null  int64 \n",
      " 3   Verdict     12948 non-null  object\n",
      " 4   Evidence    12948 non-null  object\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 505.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df['Context_ID'] = df['Context_ID'].astype(int)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Claim_ID</th>\n",
       "      <th>Claim</th>\n",
       "      <th>Verdict</th>\n",
       "      <th>Evidence</th>\n",
       "      <th>Context_ID</th>\n",
       "      <th>Context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Nữ du khách người Nga bị voi tấn công và gãy c...</td>\n",
       "      <td>HỖ TRỢ</td>\n",
       "      <td>Nữ du khách người Nga đã bị gãy chân, người cò...</td>\n",
       "      <td>10000</td>\n",
       "      <td>Nữ du khách bị voi tóm lấy, thả xuống đất khi ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Sự việc xảy ra khi nạn nhân đang chuẩn bị trèo...</td>\n",
       "      <td>HỖ TRỢ</td>\n",
       "      <td>Sự việc xảy ra trong lúc nạn nhân đang chờ để ...</td>\n",
       "      <td>10000</td>\n",
       "      <td>Nữ du khách bị voi tóm lấy, thả xuống đất khi ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Nữ du khách người Nga không bị gãy chân mà chỉ...</td>\n",
       "      <td>PHỦ NHẬN</td>\n",
       "      <td>Nữ du khách người Nga đã bị gãy chân, người cò...</td>\n",
       "      <td>10000</td>\n",
       "      <td>Nữ du khách bị voi tóm lấy, thả xuống đất khi ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Sự việc không xảy ra khi nạn nhân đang chuẩn b...</td>\n",
       "      <td>PHỦ NHẬN</td>\n",
       "      <td>Sự việc xảy ra trong lúc nạn nhân đang chờ để ...</td>\n",
       "      <td>10000</td>\n",
       "      <td>Nữ du khách bị voi tóm lấy, thả xuống đất khi ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Cửa hàng đã tạm thời đóng cửa từ ngày 8/5 đến ...</td>\n",
       "      <td>HỖ TRỢ</td>\n",
       "      <td>Trong bài viết, chủ quán cho hay sẽ tạm thời d...</td>\n",
       "      <td>10001</td>\n",
       "      <td>Vụ dòi bò lúc nhúc trong miếng pate: Quán tạm ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Claim_ID                                              Claim   Verdict  \\\n",
       "0        0  Nữ du khách người Nga bị voi tấn công và gãy c...    HỖ TRỢ   \n",
       "1        1  Sự việc xảy ra khi nạn nhân đang chuẩn bị trèo...    HỖ TRỢ   \n",
       "2        2  Nữ du khách người Nga không bị gãy chân mà chỉ...  PHỦ NHẬN   \n",
       "3        3  Sự việc không xảy ra khi nạn nhân đang chuẩn b...  PHỦ NHẬN   \n",
       "4        4  Cửa hàng đã tạm thời đóng cửa từ ngày 8/5 đến ...    HỖ TRỢ   \n",
       "\n",
       "                                            Evidence  Context_ID  \\\n",
       "0  Nữ du khách người Nga đã bị gãy chân, người cò...       10000   \n",
       "1  Sự việc xảy ra trong lúc nạn nhân đang chờ để ...       10000   \n",
       "2  Nữ du khách người Nga đã bị gãy chân, người cò...       10000   \n",
       "3  Sự việc xảy ra trong lúc nạn nhân đang chờ để ...       10000   \n",
       "4  Trong bài viết, chủ quán cho hay sẽ tạm thời d...       10001   \n",
       "\n",
       "                                             Context  \n",
       "0  Nữ du khách bị voi tóm lấy, thả xuống đất khi ...  \n",
       "1  Nữ du khách bị voi tóm lấy, thả xuống đất khi ...  \n",
       "2  Nữ du khách bị voi tóm lấy, thả xuống đất khi ...  \n",
       "3  Nữ du khách bị voi tóm lấy, thả xuống đất khi ...  \n",
       "4  Vụ dòi bò lúc nhúc trong miếng pate: Quán tạm ...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_df = pd.merge(df, context, left_on='Context_ID', right_on='ID', how='inner')\n",
    "context_df.drop(columns='Context_ID', inplace=True)\n",
    "context_df.rename(columns={'ID_x': 'Claim_ID', 'ID_y': 'Context_ID','Label': 'Verdict'}, inplace=True)\n",
    "df = context_df\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter, RecursiveCharacterTextSplitter\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_context = context_df['Context'].tolist()\n",
    "list_claim = context_df['Claim'].tolist()\n",
    "ID = context_df['Claim_ID'].tolist()\n",
    "model = SentenceTransformer(\"hiieu/halong_embedding\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evidence = []\n",
    "\n",
    "def cosine_similarity(a, b):\n",
    "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    separators=['. ', ', '],\n",
    "    chunk_size=256,\n",
    "    chunk_overlap=70,\n",
    ")\n",
    "threshold = 0.85\n",
    "start = time.time()\n",
    "\n",
    "for i in range(len(list_context)):\n",
    "  raw_text = list_context[i]\n",
    "  query = list_claim[i]\n",
    "  chunks = text_splitter.split_text(raw_text)\n",
    "\n",
    "  embeddings = model.encode(chunks)\n",
    "\n",
    "  query_embedding = model.encode([query])\n",
    "  similarities = [cosine_similarity(query_embedding, embedding) for embedding in embeddings]\n",
    "\n",
    "  best_match_idx = np.argmax(similarities)\n",
    "  best_match_chunk = chunks[best_match_idx]\n",
    "\n",
    "  evidence.append(best_match_chunk)\n",
    "\n",
    "df_kq = pd.DataFrame({'ID_Claim': ID, 'evidence': evidence})\n",
    "df_kq.to_csv('Final_210_70.csv', index=False)\n",
    "display(df_kq.head())\n",
    "display(df_kq.verdict.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verdicts = []\n",
    "evidences = []\n",
    "\n",
    "def cosine_similarity(a, b):\n",
    "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    separators=['. ', ', '],\n",
    "    chunk_size=256,\n",
    "    chunk_overlap=100,\n",
    ")\n",
    "\n",
    "threshold = 0.85\n",
    "\n",
    "for i in range(len(list_context)):\n",
    "    raw_text = list_context[i]\n",
    "    query = list_claim[i]\n",
    "    chunks = text_splitter.split_text(raw_text)\n",
    "\n",
    "    embeddings = model.encode(chunks)\n",
    "\n",
    "    query_embedding = model.encode([query])\n",
    "    similarities = [cosine_similarity(query_embedding, embedding) for embedding in embeddings]\n",
    "\n",
    "    if isinstance(chunks, list):\n",
    "        top_k_indices = np.argsort(similarities)[-5:][::-1]  # Get indices of top 5 similarities in descending order\n",
    "        top_k_chunks = [chunks[int(idx)] for idx in top_k_indices]\n",
    "        top_k_similarities = [similarities[int(idx)] for idx in top_k_indices]\n",
    "        top_k_verdicts = [0 if similarity > threshold else 1 for similarity in top_k_similarities]\n",
    "\n",
    "        verdicts.append(top_k_verdicts)\n",
    "        evidences.append(top_k_chunks)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "default_value = None  # You can change this to any default value you want\n",
    "\n",
    "df_kq = pd.DataFrame({\n",
    "    'ID_Claim': ID,\n",
    "    'verdict_1': [v[0] if len(v) > 0 else default_value for v in verdicts],\n",
    "    'verdict_2': [v[1] if len(v) > 1 else default_value for v in verdicts],\n",
    "    'verdict_3': [v[2] if len(v) > 2 else default_value for v in verdicts],\n",
    "    'verdict_4': [v[3] if len(v) > 3 else default_value for v in verdicts],\n",
    "    'verdict_5': [v[4] if len(v) > 4 else default_value for v in verdicts],\n",
    "    'evidence_1': [e[0] if len(e) > 0 else \"\" for e in evidences],\n",
    "    'evidence_2': [e[1] if len(e) > 1 else \"\" for e in evidences],\n",
    "    'evidence_3': [e[2] if len(e) > 2 else \"\" for e in evidences],\n",
    "    'evidence_4': [e[3] if len(e) > 3 else \"\" for e in evidences],\n",
    "    'evidence_5': [e[4] if len(e) > 4 else \"\" for e in evidences]\n",
    "})\n",
    "df_kq.to_csv('Final_256_100.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BM25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from rank_bm25 import BM25Okapi\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "\n",
    "# Hàm để tìm evidence trong context cho mỗi claim\n",
    "def find_evidence(claim, context):\n",
    "    # Tách context thành các câu\n",
    "    context_sentences = sent_tokenize(context)\n",
    "    \n",
    "    # Tokenize các câu trong context và claim\n",
    "    tokenized_context = [word_tokenize(sentence) for sentence in context_sentences]\n",
    "    tokenized_claim = word_tokenize(claim)\n",
    "    \n",
    "    # Tạo mô hình BM25\n",
    "    bm25 = BM25Okapi(tokenized_context)\n",
    "    \n",
    "    # Tìm các đoạn liên quan nhất cho claim\n",
    "    scores = bm25.get_scores(tokenized_claim)\n",
    "    ranked_sentences = sorted(zip(scores, context_sentences), reverse=True)\n",
    "    \n",
    "    # Lấy câu có điểm số cao nhất\n",
    "    best_sentence = ranked_sentences[0][1] if ranked_sentences else \"\"\n",
    "    \n",
    "    return best_sentence\n",
    "\n",
    "# Áp dụng hàm tìm evidence cho mỗi dòng trong DataFrame\n",
    "df['Evidence_Predict'] = df.apply(lambda row: find_evidence(row['Claim'], row['Context']), axis=1)\n",
    "\n",
    "# Lưu kết quả vào tệp CSV mới\n",
    "df.to_csv('output_with_evidence.csv', index=False)\n",
    "\n",
    "print(\"Đã tìm kiếm evidence và lưu kết quả vào tệp 'output_with_evidence.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from rank_bm25 import BM25Okapi\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "\n",
    "# Hàm để tìm top 5 evidence trong context cho mỗi claim\n",
    "def find_top_5_evidence(claim, context):\n",
    "    # Tách context thành các câu\n",
    "    context_sentences = sent_tokenize(context)\n",
    "    \n",
    "    # Tokenize các câu trong context và claim\n",
    "    tokenized_context = [word_tokenize(sentence) for sentence in context_sentences]\n",
    "    tokenized_claim = word_tokenize(claim)\n",
    "    \n",
    "    # Tạo mô hình BM25\n",
    "    bm25 = BM25Okapi(tokenized_context)\n",
    "    \n",
    "    # Tìm các đoạn liên quan nhất cho claim\n",
    "    scores = bm25.get_scores(tokenized_claim)\n",
    "    ranked_sentences = sorted(zip(scores, context_sentences), reverse=True)\n",
    "    \n",
    "    # Lấy top 5 câu có điểm số cao nhất\n",
    "    top_5_sentences = [sentence for _, sentence in ranked_sentences[:5]]\n",
    "    \n",
    "    # Nếu ít hơn 5 câu, điền thêm bằng chuỗi rỗng\n",
    "    while len(top_5_sentences) < 5:\n",
    "        top_5_sentences.append(\"\")\n",
    "    \n",
    "    return top_5_sentences\n",
    "\n",
    "# Áp dụng hàm tìm top 5 evidence cho mỗi dòng trong DataFrame\n",
    "df[['Evidence_Predict_1', 'Evidence_Predict_2', 'Evidence_Predict_3', 'Evidence_Predict_4', 'Evidence_Predict_5']] = df.apply(\n",
    "    lambda row: pd.Series(find_top_5_evidence(row['Claim'], row['Context'])), axis=1)\n",
    "\n",
    "# Lưu kết quả vào tệp CSV mới\n",
    "df.to_csv('output_with_top5_evidence.csv', index=False)\n",
    "\n",
    "print(\"Đã tìm kiếm top 5 evidence và lưu kết quả vào tệp 'output_with_top5_evidence.csv'.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
